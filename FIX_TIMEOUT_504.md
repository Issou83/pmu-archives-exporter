# ğŸ”§ Fix : Timeout 504 Gateway Timeout

## âŒ ProblÃ¨me IdentifiÃ©

**SymptÃ´me** : Erreur `504 Gateway Timeout` sur les requÃªtes API

- **URL testÃ©e** : `https://pmu-archives-exporter.vercel.app/api/archives?source=turf-fr&years=2025&months=mai&reunionNumbers=1&countries=FR`
- **Cause** : Le scraping dÃ©passe la limite de 60 secondes de Vercel
- **Impact** : MÃªme sans rapports d'arrivÃ©e, le scraping de base prend trop de temps

## ğŸ” Analyse

### Limites Vercel

- **Timeout maximum** : 60 secondes pour les fonctions serverless
- **Configuration** : `vercel.json` dÃ©finit `maxDuration: 60`

### Causes du Timeout

1. **Pas de timeout sur les requÃªtes fetch** : Les requÃªtes peuvent bloquer indÃ©finiment
2. **Chargement de robots.txt** : Peut prendre plusieurs secondes
3. **Scraping de la page d'archives** : Peut Ãªtre lent selon la taille de la page
4. **Pas de timeout global** : Le scraping peut dÃ©passer 60 secondes sans contrÃ´le

## âœ… Corrections AppliquÃ©es

### 1. Timeout Global sur le Scraping

**Fichier** : `api/archives.js` (lignes 231-250)

```javascript
// Timeout global de 50 secondes (marge de 10s avant la limite Vercel)
const SCRAPING_TIMEOUT = 50000; // 50 secondes

const scrapingPromise = scrapeTurfFrArchives(
  years,
  months,
  includeArrivalReports
);
const timeoutPromise = new Promise((_, reject) => {
  setTimeout(() => {
    reject(
      new Error('Scraping timeout: Le scraping prend trop de temps (>50s)...')
    );
  }, SCRAPING_TIMEOUT);
});

reunions = await Promise.race([scrapingPromise, timeoutPromise]);
```

**Impact** : ArrÃªte le scraping aprÃ¨s 50 secondes pour Ã©viter le timeout Vercel

### 2. Timeout sur les RequÃªtes Fetch

**Fichier** : `api/scrapers/turfScraper.js` (lignes 122-145)

```javascript
// Timeout de 10 secondes pour la page d'archives
const controller = new AbortController();
const timeoutId = setTimeout(() => controller.abort(), 10000); // 10 secondes max

response = await fetch(url, {
  signal: controller.signal,
  // ...
});
```

**Impact** : Chaque requÃªte fetch s'arrÃªte aprÃ¨s 10 secondes maximum

### 3. Timeout sur robots.txt

**Fichier** : `api/scrapers/turfScraper.js` (lignes 1199-1210)

```javascript
// Timeout de 5 secondes pour robots.txt
try {
  const robotsPromise = fetchRobotsTxt('https://www.turf-fr.com');
  const robotsTimeout = new Promise((_, reject) => {
    setTimeout(() => reject(new Error('robots.txt timeout')), 5000);
  });
  robotsRules = await Promise.race([robotsPromise, robotsTimeout]);
} catch (error) {
  // Utiliser un dÃ©lai par dÃ©faut si robots.txt Ã©choue
  crawlDelay = 400; // DÃ©lai par dÃ©faut
}
```

**Impact** : Si robots.txt prend trop de temps, on utilise un dÃ©lai par dÃ©faut

## ğŸ“Š RÃ©sultats Attendus

### Avant les Corrections

- âŒ Timeout 504 : FrÃ©quent pour les requÃªtes avec plusieurs mois
- âŒ Pas de contrÃ´le : Le scraping peut bloquer indÃ©finiment
- âŒ Erreurs silencieuses : Pas de message clair pour l'utilisateur

### AprÃ¨s les Corrections

- âœ… Timeout contrÃ´lÃ© : ArrÃªt aprÃ¨s 50 secondes avec message clair
- âœ… Timeouts individuels : Chaque requÃªte a un timeout de 10s
- âœ… Gestion gracieuse : Message d'erreur explicite pour l'utilisateur

## ğŸ§ª Tests

### Test 1 : RequÃªte Simple

```bash
curl "https://pmu-archives-exporter.vercel.app/api/archives?source=turf-fr&years=2025&months=mai&reunionNumbers=1&countries=FR"
```

**RÃ©sultat attendu** :

- âœ… RÃ©ponse en moins de 50 secondes
- âœ… OU erreur 504 avec message clair si timeout

### Test 2 : RequÃªte Complexe

```bash
curl "https://pmu-archives-exporter.vercel.app/api/archives?source=turf-fr&years=2025&months=mai,fevrier"
```

**RÃ©sultat attendu** :

- âœ… RÃ©ponse en moins de 50 secondes
- âœ… OU erreur 504 avec message suggÃ©rant de rÃ©duire le nombre de mois

## ğŸš€ DÃ©ploiement

1. âœ… Code corrigÃ©
2. âœ… Build rÃ©ussi
3. â³ Commit et push en attente
4. â³ RedÃ©ploiement Vercel en attente

## ğŸ“ Notes Techniques

- Les timeouts sont configurables et peuvent Ãªtre ajustÃ©s si nÃ©cessaire
- Le timeout global de 50s laisse une marge de 10s avant la limite Vercel (60s)
- Les timeouts individuels (10s pour fetch, 5s pour robots.txt) empÃªchent les blocages
- Les erreurs sont maintenant explicites et aident l'utilisateur Ã  comprendre le problÃ¨me
